2023-02-01 17:39:08   train_only.py --dataset_folder /content/small --groups_num 1 --epochs_num 3 --batch_size 16 --iterations_per_epoch 5000 --loss_function cosface --hflip 0 --rgrayscale 0 --rerasing 0
2023-02-01 17:39:08   Arguments: Namespace(L=2, M=10, N=5, alpha=30, augmentation_device='cuda', backbone='resnet18', batch_size=16, best_model=None, brightness=0.7, classifiers_lr=0.01, contrast=0.7, dataset_folder='/content/small', device='cuda', epochs_num=3, fc_output_dim=512, gblur=0.25, groups_num=1, hflip=0.0, hue=0.5, infer_batch_size=16, iterations_per_epoch=5000, loss_function='cosface', lr=1e-05, min_images_per_class=10, num_workers=8, positive_dist_threshold=25, random_resized_crop=0.5, rerasing=0.0, resume_model=None, resume_train=None, rgrayscale=0.0, saturation=0.7, save_dir='default', seed=0, test_set_folder='/content/small/test', train_set_folder='/content/small/train', use_amp16=False, val_set_folder='/content/small/val')
2023-02-01 17:39:08   The outputs are being saved in AML23-CosPlace/model/results/best_2023-02-01_17-39-08
2023-02-01 17:39:08   Train only layer3 and layer4 of the resnet18, freeze the previous ones
2023-02-01 17:39:09   There are 1 GPUs and 2 CPUs.
2023-02-01 17:39:11   Using cached dataset cache/small_M10_N5_mipc10.torch
2023-02-01 17:39:11   Using 1 groups
2023-02-01 17:39:11   The 1 groups have respectively the following number of classes [5965]
2023-02-01 17:39:11   The 1 groups have respectively the following number of images [59650]
2023-02-01 17:39:11   Start training ...
2023-02-01 17:39:11   There are 5965 classes for the first group, each epoch has 5000 iterations with batch_size 16, therefore the model sees each class (on average) 13.4 times per epoch
2023-02-01 17:39:12   Validation set: < val - #q: 7993; #db: 8015 >
2023-02-01 17:58:02   Epoch 00 in 0:18:50, loss = 14.2859
2023-02-01 17:58:02   Extracting database descriptors for evaluation/testing
2023-02-01 17:59:01   Extracting queries descriptors for evaluation/testing using batch size 1
2023-02-01 18:00:43   Calculating recalls
2023-02-01 18:00:45   Epoch 00 in 0:21:33, < val - #q: 7993; #db: 8015 >: R@1: 69.8, R@5: 81.8
2023-02-01 18:19:42   Epoch 01 in 0:18:56, loss = 6.9839
2023-02-01 18:19:42   Extracting database descriptors for evaluation/testing
2023-02-01 18:20:41   Extracting queries descriptors for evaluation/testing using batch size 1
2023-02-01 18:22:21   Calculating recalls
2023-02-01 18:22:22   Epoch 01 in 0:21:36, < val - #q: 7993; #db: 8015 >: R@1: 75.8, R@5: 86.2
2023-02-01 18:41:16   Epoch 02 in 0:18:53, loss = 5.2443
2023-02-01 18:41:16   Extracting database descriptors for evaluation/testing
2023-02-01 18:42:13   Extracting queries descriptors for evaluation/testing using batch size 1
2023-02-01 18:43:52   Calculating recalls
2023-02-01 18:43:54   Epoch 02 in 0:21:31, < val - #q: 7993; #db: 8015 >: R@1: 78.1, R@5: 87.9
2023-02-01 18:43:54   Trained for 03 epochs, in total in 1:04:46
2023-02-01 18:43:54   Best model is saved in AML23-CosPlace/model/results/best_2023-02-01_17-39-08/best_model.pth
2023-02-01 18:43:54   Experiment finished (without any errors)

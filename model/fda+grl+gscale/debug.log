2023-02-04 11:26:06   train_only.py --dataset_folder /content/small --groups_num 1 --epochs_num 3 --batch_size 32 --loss_function cosface --grl True --rgrayscale 0.25
2023-02-04 11:26:06   Arguments: Namespace(L=2, M=10, N=5, alpha=30, augmentation_device='cuda', backbone='resnet18', batch_size=32, best_model=None, brightness=0.7, classifiers_lr=0.01, contrast=0.7, dataset_folder='/content/small', device='cuda', epochs_num=3, fc_output_dim=512, gblur=0, grl=True, groups_num=1, hflip=0, hue=0.5, infer_batch_size=16, iterations_per_epoch=10000, loss_function='cosface', lr=1e-05, min_images_per_class=10, num_workers=8, positive_dist_threshold=25, random_resized_crop=0.5, rerasing=0, resume_model=None, resume_train=None, rgrayscale=0.25, saturation=0.7, save_dir='default', seed=0, test_set_folder='/content/small/test', train_set_folder='/content/small/train', use_amp16=False, val_set_folder='/content/small/val')
2023-02-04 11:26:06   The outputs are being saved in AML23-CosPlace/model/results/best_2023-02-04_11-26-06
2023-02-04 11:26:07   Train only layer3 and layer4 of the resnet18, freeze the previous ones
2023-02-04 11:26:07   There are 1 GPUs and 12 CPUs.
2023-02-04 11:26:11   Cached dataset cache/small_M10_N5_mipc10.torch does not exist, I'll create it now.
2023-02-04 11:26:11   Searching training images in /content/small/train
2023-02-04 11:26:12   Found 79574 images
2023-02-04 11:26:12   For each image, get its UTM east, UTM north and heading from its path
2023-02-04 11:26:12   For each image, get class and group to which it belongs
2023-02-04 11:26:12   Group together images belonging to the same class
2023-02-04 11:26:12   Group together classes belonging to the same group
2023-02-04 11:26:13   GrlDataset has 3 domain classes
2023-02-04 11:26:13   Using 1 groups
2023-02-04 11:26:13   The 1 groups have respectively the following number of classes [5965]
2023-02-04 11:26:13   The 1 groups have respectively the following number of images [79574]
2023-02-04 11:26:13   Start training ...
2023-02-04 11:26:13   There are 5965 classes for the first group, each epoch has 10000 iterations with batch_size 32, therefore the model sees each class (on average) 53.6 times per epoch
2023-02-04 11:26:13   Validation set: < val - #q: 15986; #db: 8015 >
2023-02-04 11:51:29   Epoch 00 in 0:25:16, loss = 8.3498
2023-02-04 11:51:29   Average GRL epoch loss (* alpha = 0.1): 0.0578
2023-02-04 11:51:29   Extracting database descriptors for evaluation/testing
2023-02-04 11:51:42   Extracting queries descriptors for evaluation/testing using batch size 1
2023-02-04 11:53:33   Calculating recalls
2023-02-04 11:53:35   Epoch 00 in 0:27:22, < val - #q: 15986; #db: 8015 >: R@1: 77.7, R@5: 87.5
2023-02-04 12:18:48   Epoch 01 in 0:25:12, loss = 3.6875
2023-02-04 12:18:48   Average GRL epoch loss (* alpha = 0.1): 0.1179
2023-02-04 12:18:48   Extracting database descriptors for evaluation/testing
2023-02-04 12:19:01   Extracting queries descriptors for evaluation/testing using batch size 1
2023-02-04 12:20:53   Calculating recalls
2023-02-04 12:20:55   Epoch 01 in 0:27:19, < val - #q: 15986; #db: 8015 >: R@1: 80.7, R@5: 89.3
2023-02-04 12:46:10   Epoch 02 in 0:25:14, loss = 2.6896
2023-02-04 12:46:10   Average GRL epoch loss (* alpha = 0.1): 0.1775
2023-02-04 12:46:10   Extracting database descriptors for evaluation/testing
2023-02-04 12:46:23   Extracting queries descriptors for evaluation/testing using batch size 1
2023-02-04 12:48:15   Calculating recalls
2023-02-04 12:48:18   Epoch 02 in 0:27:22, < val - #q: 15986; #db: 8015 >: R@1: 81.9, R@5: 90.0
2023-02-04 12:48:18   Trained for 03 epochs, in total in 1:22:12
2023-02-04 12:48:18   Best model is saved in AML23-CosPlace/model/results/best_2023-02-04_11-26-06/best_model.pth
2023-02-04 12:48:18   Experiment finished (without any errors)
